{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.regression.linear_model import yule_walker\n",
    "#from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'WTI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-903063b1de37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#                    end='2019-05-01',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#                    progress=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mAMZN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Change %'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWTI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mWTI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAMZN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Open'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Volume'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Change %'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Change %'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WTI' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "AMZN = data = yf.download('CL=F', start ='2000-08-23' , end='2021-04-22')\n",
    "\n",
    "#WTI = yf.download('CL=F', \n",
    " #                     start='2017-01-01', \n",
    "  #                    end='2019-05-01', \n",
    "  #                    progress=False)\n",
    "AMZN['Change %'] = 100* ((WTI['Adj Close'] / WTI['Open']) - 1)\n",
    "all_data = AMZN[['Adj Close','Open', 'High', 'Low', 'Close', 'Volume', 'Change %']].round(2)\n",
    "all_data['Change %'].plot()\n",
    "#print(\"There are \"+ str(WTI[:int(len(WTI) * 0.6546 )].shape[0]) + \" observations in the training data\")\n",
    "#print(\"There are \"+ str(WTI[int(len(WTI) * 0.6546 ):].shape[0]) + \" observations in the test data\")\n",
    "\n",
    "#AMZN = pd.read_csv(\"1h_data.csv\")\n",
    "#AMZN[\"Date\"] = AMZN[\"Unnamed: 0\"]\n",
    "#AMZN.set_index(\"Date\")\n",
    "#AMZN.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "#all_data = AMZN[['Adj Close','Open', 'High', 'Low', 'Close', 'Volume']].round(2)\n",
    "#all_data.head(10)\n",
    "cut = int(len(all_data)*0.6546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Open'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \"+ str(all_data[: cut].shape[0]) + \" observations in the training data\")\n",
    "print(\"There are \"+ str(all_data[cut:].shape[0]) + \" observations in the test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test(all_data,time_steps,for_periods):\n",
    "    '''\n",
    "    input: \n",
    "      data: dataframe with dates and price data\n",
    "    output:\n",
    "      X_train, y_train: data from 2013/1/1-2018/12/31\n",
    "      X_test:  data from 2019 -\n",
    "      sc:      insantiated MinMaxScaler object fit to the training data\n",
    "    '''\n",
    "    # create training and test set\n",
    "    ts_train = all_data[:cut].iloc[:,0:1].values\n",
    "    ts_test  = all_data[cut:].iloc[:,0:1].values\n",
    "    ts_train_len = len(ts_train)\n",
    "    ts_test_len = len(ts_test)\n",
    "\n",
    "    # create training data of s samples and t time steps\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    y_train_stacked = []\n",
    "    for i in range(time_steps,ts_train_len-1): \n",
    "        X_train.append(ts_train[i-time_steps:i,0])\n",
    "        y_train.append(ts_train[i:i+for_periods,0])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # Reshaping X_train for efficient modelling\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
    "\n",
    "    inputs = pd.concat((all_data[\"Change %\"][:cut], all_data[\"Change %\"][ cut :]),axis=0).values\n",
    "    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "\n",
    "    # Preparing X_test\n",
    "    X_test = []\n",
    "    for i in range(time_steps,ts_test_len+time_steps-for_periods):\n",
    "        X_test.append(inputs[i-time_steps:i,0])\n",
    "        \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "    return X_train, y_train , X_test\n",
    "\n",
    "X_train, y_train, X_test = ts_train_test(all_data,5,2)\n",
    "X_train.shape[0],X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the 3-D shape to a data frame so we can see: \n",
    "X_train_see = pd.DataFrame(np.reshape(X_train, (X_train.shape[0],X_train.shape[1])))\n",
    "y_train_see = pd.DataFrame(y_train)\n",
    "pd.concat([X_train_see,y_train_see],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the 3-D shape to a data frame so we can see: \n",
    "X_test_see = pd.DataFrame(np.reshape(X_test, (X_test.shape[0],X_test.shape[1])))\n",
    "pd.DataFrame(X_test_see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \" + str(X_train.shape[0]) + \" samples in the training data\")\n",
    "print(\"There are \" + str(X_test.shape[0]) + \" samples in the test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(preds):\n",
    "    actual_pred = pd.DataFrame(columns = ['Change %', 'prediction'])\n",
    "    name = all_data.iloc[cut].name\n",
    "    actual_pred['Change %'] = all_data.loc[name:,'Change %'][0:len(preds)]\n",
    "    actual_pred['prediction'] = preds[:,0]\n",
    "\n",
    "    from keras.metrics import MeanSquaredError\n",
    "    m = MeanSquaredError()\n",
    "    m.update_state(np.array(actual_pred['Change %']),np.array(actual_pred['prediction']))\n",
    "    \n",
    "    return (m.result().numpy(), actual_pred.plot() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_normalize(all_data,time_steps,for_periods):\n",
    "    '''\n",
    "    input: \n",
    "      data: dataframe with dates and price data\n",
    "    output:\n",
    "      X_train, y_train: data from 2013/1/1-2018/12/31\n",
    "      X_test:  data from 2019 -\n",
    "      sc:      insantiated MinMaxScaler object fit to the training data\n",
    "    '''\n",
    "    # create training and test set\n",
    "    ts_train = all_data[:cut].iloc[:,0:1].values\n",
    "    ts_test  = all_data[cut:].iloc[:,0:1].values\n",
    "    ts_train_len = len(ts_train)\n",
    "    ts_test_len = len(ts_test)\n",
    "\n",
    "    # scale the data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    ts_train_scaled = sc.fit_transform(ts_train)\n",
    "\n",
    "    # create training data of s samples and t time steps\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    y_train_stacked = []\n",
    "    for i in range(time_steps,ts_train_len-1): \n",
    "        X_train.append(ts_train_scaled[i-time_steps:i,0])\n",
    "        y_train.append(ts_train_scaled[i:i+for_periods,0])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # Reshaping X_train for efficient modelling\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
    "\n",
    "    inputs = pd.concat((all_data[\"Change %\"][: cut], all_data[\"Change %\"][cut :]),axis=0).values\n",
    "    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs  = sc.transform(inputs)\n",
    "\n",
    "    # Preparing X_test\n",
    "    X_test = []\n",
    "    for i in range(time_steps,ts_test_len+time_steps-for_periods):\n",
    "        X_test.append(inputs[i-time_steps:i,0])\n",
    "        \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "    return X_train, y_train , X_test, sc\n",
    "\n",
    "X_train, y_train, X_test, sc = ts_train_test_normalize(all_data,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_test, sc):\n",
    "    # create a model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "    from keras.optimizers import SGD\n",
    "    \n",
    "    # The LSTM architecture\n",
    "    my_LSTM_model = Sequential()\n",
    "    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "    my_LSTM_model.add(LSTM(units=50, activation='tanh'))\n",
    "    my_LSTM_model.add(Dense(units=2))\n",
    "\n",
    "    # Compiling\n",
    "    my_LSTM_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
    "    # Fitting to the training set\n",
    "    my_LSTM_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)\n",
    "\n",
    "    LSTM_prediction = my_LSTM_model.predict(X_test)\n",
    "    LSTM_prediction = sc.inverse_transform(LSTM_prediction)\n",
    "\n",
    "    return my_LSTM_model, LSTM_prediction\n",
    "\n",
    "my_LSTM_model, LSTM_prediction = LSTM_model(X_train, y_train, X_test, sc)\n",
    "LSTM_prediction[1:10]\n",
    "actual_pred_plot(LSTM_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_regularization(X_train, y_train, X_test, sc):\n",
    "\n",
    "    # create a model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, SimpleRNN, LSTM\n",
    "    from keras.optimizers import SGD\n",
    "    from keras.layers import Dropout\n",
    "    \n",
    "    # The LSTM architecture\n",
    "    my_LSTM_model = Sequential()\n",
    "    # First LSTM layer with Dropout regularisation\n",
    "    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "    my_LSTM_model.add(Dropout(0.2))\n",
    "    # Second LSTM layer\n",
    "    my_LSTM_model.add(LSTM(units=50, return_sequences=True, activation='tanh'))\n",
    "    my_LSTM_model.add(Dropout(0.2))\n",
    "    \n",
    "    # Third LSTM layer\n",
    "    my_LSTM_model.add(LSTM(units=50, return_sequences=True, activation='tanh'))\n",
    "    my_LSTM_model.add(Dropout(0.2))\n",
    "    # Fourth LSTM layer\n",
    "    my_LSTM_model.add(LSTM(units=50, activation='tanh'))\n",
    "    my_LSTM_model.add(Dropout(0.2))\n",
    "    # The output layer\n",
    "    my_LSTM_model.add(Dense(units=1))\n",
    "    # Compiling the RNN\n",
    "    my_LSTM_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n",
    "    # Fitting to the training set\n",
    "    my_LSTM_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)\n",
    "\n",
    "    LSTM_predictions = my_LSTM_model.predict(X_test)\n",
    "    LSTM_predictions = sc.inverse_transform(LSTM_predictions)\n",
    "\n",
    "    return my_LSTM_model, LSTM_predictions\n",
    "\n",
    "my_LSTM_model, LSTM_predictions = LSTM_model_regularization(X_train, y_train, X_test, sc)\n",
    "LSTM_predictions[1:10]\n",
    "actual_pred_plot(LSTM_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''result = LSTM_prediction[:,0]   \n",
    "    \n",
    "f= open(\"1h-pred-lstm.txt\",\"w\")\n",
    "\n",
    "for i in range(0,len(result)):\n",
    "    f.write(str(result[i]) +\",\")    \n",
    "\n",
    "f.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
